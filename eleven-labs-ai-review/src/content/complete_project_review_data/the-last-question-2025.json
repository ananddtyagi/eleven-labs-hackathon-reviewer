{
    "project_details": "<div>\n<h2>Inspiration</h2>\n<p>12 years ago I spent a weekend hacking on a web-based, interactive version of \"The Last Question\" by Isaac Asimov, using jQuery and (at the time) cutting-edge CSS text animation. It's still up here (but a bit janky now) <a href=\"https://github.com/tvararu/the-last-question\" rel=\"nofollow\">https://github.com/tvararu/the-last-question</a></p>\n<p>Recently with the advent of gen AI I've been thinking you could do a lot more: generate images from the book, full audio narration, you could even diverge from the plot and ask philosophical questions to the characters directly if you wanted to. You could personalise the experience a lot more to the reader.</p>\n<p>If you're familiar with the story, you know it also sort of predicted reasoning models, but I won't spoil more! (You should read it, takes 25mins!)</p>\n<h2>What it does</h2>\n<p>The Last Question (2025) is an AI storyteller where you talk to a conversational agent. The agent has the full text of the book in their context window and will attempt to faithfully guide you through. You can ask it questions at any point, and they'll do their best to answer.</p>\n<p>There is also a tiny LLM pipeline that takes every message in the conversation, parses it, and then generates an image using Flux on fal.</p>\n<h2>How we built it</h2>\n<p>First I went on ElevenLabs and checked out what's new. After experimenting with conversational AI agents, specifically the \"video game character\" example, I found that the agent was producing decent results and got to writing up an interface.</p>\n<p>I did start out on Lovable, but I couldn't find an easy way to get it to follow the Quickstart guide on AI agents from ElevenLabs' docs. I think I could have generated the boilerplate separately and then imported it as a GitHub project and that probably would have worked better.</p>\n<p>So I integrated an ElevenLabs conversational AI agent, using the Next.js starter kit from the official docs using the React client library. Fal AI JS client library, using a proxy. Deployed to Vercel. Mostly vibe-coded in Cursor (Claude 3.5 Sonnet New) using macOS' built-in voice transcription, no superwhisper or anything else.</p>\n<p>I decided to keep everything in one file, and there's not much error handling or automated testing.</p>\n<h2>Challenges we ran into</h2>\n<ul>\n<li>The agent really likes to end every message with \"Would you like to continue?\" and trying to prompt it out causes it to ramble endlessly and reply with really long messages</li>\n<li>The conversation log is a bit janky because messages come in one chunk instead of using something like streaming</li>\n<li>Full duplex audio doesn't feel like the greatest fit for this usecase; rather generate chunks of text, use TTS, then generate replies on the user's behalf. I thought about building a \"faux voice mode\" where you don't use the user's microphone but instead generate TTS and send that back in the websocket, but would have been quite involved</li>\n<li>Unclear how to pause/resume the conversation with the agent using the official library, maybe not a capability yet?</li>\n<li>Getting nice looking images from Flux is possible but I'd probably have to spend a lot more time futzing the prompts, currently I'd say the results are a bit hit and miss and not sure they're a net positive on the experience</li>\n<li>I used up ~25% of my ElevenLabs credit just with testing, I hope the leftover allowance is enough in case judges want to test it out</li>\n</ul>\n<h2>Accomplishments that we're proud of</h2>\n<p>I was really happy with how quickly I got a proof of concept working.</p>\n<p>This was my first time vibe-coding and I had a lot of fun.</p>\n<h2>What we learned</h2>\n<p>I definitely think current TTS and image gen tech is up to scratch for this usecase, but as usual, the idea isn't new, but execution is what matters.</p>\n<p>I don't feel like I nailed the execution, but that's fine for a quick and dirty hackathon setting.</p>\n<h2>What's next for The Last Question (2025)</h2>\n<p>If I do end up pursuing rebuilding this into a proper experience, I'd probably not use Agent mode from ElevenLabs, because it's quite expensive and full duplex communication isn't a necessity here. I'd rather just rely on the more classic TTS options and probably generate some canned replies for the user using an LLM.</p>\n<p>Also you could generalise this idea; you could make it work for any book, like a souped up version of ElevenReader.</p>\n</div>",
    "advocate": "Let me provide a structured analysis of \"The Last Question (2025)\" based on the hackathon rubric:\n\nImpact (25%)\n- Strong potential for long-term success in digital storytelling and education\n- Highly scalable concept that could be applied to any literary work\n- Significant societal impact by making literature more interactive and accessible\n- Creates a new paradigm for engaging with classic stories through AI\n- Educational value in combining reading with interactive learning\n\nTechnical Implementation (25%)\n- Successfully integrated multiple cutting-edge technologies:\n  * ElevenLabs' conversational AI agent\n  * Next.js framework\n  * Fal AI for image generation\n  * React client library\n- Achieved functional proof-of-concept despite technical challenges\n- Clean implementation keeping everything in one file for hackathon purposes\n- Successfully deployed on Vercel for accessibility\n\nCreativity and Innovation (25%)\n- Highly innovative approach to modernizing classic literature\n- Creative use of AI to enable direct interaction with story characters\n- Novel combination of text, voice, and image generation\n- Unique approach to personalized storytelling\n- Reimagining a 12-year-old project with modern AI capabilities\n\nPitch and Presentation (25%)\n- Clear and detailed project documentation\n- Honest and transparent about challenges faced\n- Well-articulated vision for future improvements\n- Strong understanding of market positioning and potential\n- Excellent communication of technical and creative aspects\n\nStandout Strengths:\n1. Exceptional vision for transforming literary experiences\n2. Strong technical foundation with multiple AI integrations\n3. Clear pathway to commercialization and scaling\n4. Honest assessment of current limitations and future improvements\n5. Perfect alignment with current trends in AI and education\n\nThe project shows remarkable potential for revolutionizing how we interact with literature, combining multiple AI technologies in a novel way. The creator's experience and vision for future improvements demonstrate both technical capability and product understanding.",
    "critic": "Here's a critical analysis of \"The Last Question 2025\" project, focusing on potential issues and areas for improvement:\n\nImpact (25% weight) - Major Concerns:\n- Limited scalability due to high operational costs (ElevenLabs credits being depleted quickly)\n- Narrow focus on a single short story limits broader market appeal\n- No clear monetization strategy or sustainable business model\n- Questionable long-term value proposition compared to traditional reading experiences\n\nTechnical Implementation (25% weight) - Significant Weaknesses:\n- Lack of error handling and automated testing raises reliability concerns\n- All code consolidated in one file, indicating poor architectural practices\n- No proper streaming implementation for conversation logs\n- Missing crucial features like pause/resume functionality\n- Image generation results are inconsistent and \"hit or miss\"\n- Heavy reliance on third-party services without fallback options\n\nCreativity and Innovation (25% weight) - Areas of Concern:\n- Project is essentially a remake of developer's previous work\n- Core concept (interactive storytelling) isn't particularly novel\n- Heavily dependent on existing technologies without significant innovative elements\n- Limited interactive features beyond basic conversation\n- No unique selling proposition compared to existing audiobook or interactive story platforms\n\nPitch and Presentation (25% weight) - Weaknesses:\n- Documentation focuses more on technical challenges than user benefits\n- Lack of clear vision for future development\n- No demonstration of market research or target audience analysis\n- Missing metrics or data to support claims of effectiveness\n- Admittance of not \"nailing the execution\" suggests incomplete implementation\n\nAdditional Critical Points:\n1. Resource Efficiency:\n- High resource consumption (25% credits used in testing alone)\n- Potentially unsustainable cost structure\n\n2. User Experience:\n- Agent's repetitive behavior (\"Would you like to continue?\")\n- Questionable value add of image generation\n- Full duplex audio implementation may be unnecessary\n\n3. Development Approach:\n- \"Vibe-coding\" approach suggests lack of proper planning\n- Minimal attention to code quality and structure\n- No consideration for accessibility features\n\n4. Future Viability:\n- Developer already suggesting major architectural changes\n- Uncertainty about the current implementation's sustainability\n- No clear path to improvement or scaling\n\nRecommendation:\nThe project requires significant refinement and restructuring to be viable. Consider:\n- Complete architectural redesign\n- More robust error handling\n- Optimized resource usage\n- Clearer differentiation from existing solutions\n- Better defined target market and use cases\n\nThe current implementation appears more like a proof of concept than a production-ready solution, with significant technical and strategic limitations that would need to be addressed for any serious deployment.",
    "judgement": "{\n    \"summary\": \"The advocate emphasizes the project's innovative approach to digital storytelling, successful integration of multiple AI technologies, and potential for scalability across literature. They highlight the clean implementation and clear documentation. The critic points out significant resource efficiency concerns, technical limitations, architectural issues, and questions the project's long-term viability and market differentiation.\",\n    \n    \"analysis\": \"Both sides make valid points. The project shows genuine innovation in combining modern AI technologies to transform literary experiences, particularly impressive for a hackathon setting. However, the technical implementation has notable limitations and sustainability concerns. The core concept is promising, but the current execution faces significant challenges regarding costs, architecture, and user experience. The honest self-assessment in the documentation is commendable, though it also reveals many areas needing improvement.\",\n    \n    \"scores\": {\n        \"impact\": 7,\n        \"technical_implementation\": 5,\n        \"creativity_and_innovation\": 8,\n        \"pitch_and_presentation\": 7\n    },\n    \n    \"final_verdict\": \"The Last Question 2025 is an ambitious and creative project that demonstrates strong potential in modernizing literary experiences through AI. While the current implementation has significant technical and sustainability challenges, the core concept is sound and valuable. Recommendations for improvement: 1) Implement proper architecture and error handling, 2) Optimize resource usage and costs, 3) Develop a clear monetization strategy, 4) Focus on improving image generation quality, 5) Consider implementing a simpler, more sustainable approach to the AI interaction model. The project scores well on creativity and presentation but needs substantial technical refinement to be viable for production use.\"\n}",
    "scores": {
        "impact": 7,
        "technical_implementation": 5,
        "creativity_and_innovation": 8,
        "pitch_and_presentation": 7
    }
}